# 두번째 딥러닝: 보스턴 집값 예측 
### 여러개의 독립변수(x1,x2,x3...)와 하나의 종속변수(y)가 있을 때,<br/> 딥러닝으로 w1x1 + w2x2 + w3x3 ... + b(w=weight,b=bias)를 구해낸다 
1.라이브러리 사용<br/><br/>
2.과거의 데이터준비<br/><br/>
3.독립변수, 종속변수 분리
```
독립 = 보스턴[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',
            'ptratio', 'b', 'lstat']]
종속 = 보스턴[['medv']]
print(독립.shape, 종속.shape)
```
4.모델의 구조 만들기
```
X = tf.keras.layers.Input(shape=[13])
Y = tf.keras.layers.Dense(1)(X)
model = tf.keras.models.Model(X, Y)
model.compile(loss='mse')
```
> mse(mean squared error): loss계산의 한 종류

5.데이터로 모델을 fit<br/><br/>

# 세번쨰 딥러닝: 아이리스 품종 예측
### 수로 이루어진 독립변수를 수로 이루어진 종속변수로 예측하는 것은 회귀,<br/>수로 이루어진 독립변수를 문자로 이루어진 종속변수로 예측하는것은 분류.<br/>아이리스 품종 분류는 회귀 
1.라이브러리 사용<br/><br/>
2.과거의 데이터준비<br/><br/>
3.독립변수, 종속변수 분리
```
독립 = 아이리스[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]
종속 = 아이리스[['품종_setosa', '품종_versicolor', '품종_virginica']]
print(독립.shape, 종속.shape)
```
4.모델의 구조 만들기
```
X = tf.keras.layers.Input(shape=[4])
Y = tf.keras.layers.Dense(3, activation='softmax')(X)
model = tf.keras.models.Model(X, Y)
model.compile(loss='categorical_crossentropy',
              metrics='accuracy')
```
> loss 계산방식은 분류할때 쓰는 방법을 사용

5. 모델을 이용
```
# 맨 처음 데이터 5개
print(model.predict(독립[:5]))
print(종속[:5])
 
# 맨 마지막 데이터 5개
print(model.predict(독립[-5:]))
print(종속[-5:])
 

# weights & bias 출력
print(model.get_weights())
```
